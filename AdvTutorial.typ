#import math

= Tutorial 2018

== Introduction

=== Notation (åˆ†ç±»æ¨¡åž‹çš„åŸºæœ¬å®šä¹‰/PGD)

- model, hypothesis function, $h_theta: math.italic(Chi) -> R^k$ k is the number of classes
- loss function $L(h_theta (x), y)$ = $log(sum_k^(i=1) exp(h_theta (x)_j) - h_theta (x)_y)$

=== Creating an adversiarl example
With backpropagation we can compute the gradient of the loss function with respect to the input $nabla_x L(h_theta (x), y)$:
Then we can solve an optimization problem to find an adversarial example $hat(x)$:
$max_(delta in Delta) l(h_theta (x+delta), y)$
$Delta$ is an allowed perturbation set, for example, (and commonly) an $L_"infinity"$ ball.
where $Delta = {delta in R^m | ||delta|| <= epsilon}$

In theory, we would like $Delta$ to capture anything than human visually cannot distinguish (feel to be the 
"same" as the original input x), but this is hard to formalize.
The $L_"inf"$ ball provide a â€œnecessarily-but-definitely-not-close-to-sufficientâ€ condition for us to consider a classifier robust to perturbations.

we follow each step with a projection back onto the â„“âˆž ball (done by simply clipping the values that exceed Ïµ magnitude to Â±Ïµ), this is actually a procedure known as projected gradient descent (PGD). 

=== Targeted attack, æž„é€ å¯¹æŠ—æ ·æœ¬
maximize the loss of the correct class while also minimizing the loss of the target class

$max_(delta in Delta) (l(h_theta (x+delta), y) - l(h_theta (x+delta), y_"target") equiv max_(delta in Delta)(h_theta (x + delta)_(y_"target") - h_theta (x+delta)_y)$ since the log term can be canceled out.

=== Adversarial robustness and Training

- risk, training, and testing sets

The risk of a classifier is it's expectied loss under the true distribution of samples:
$R(h_theta) = E_(x,y) tilde D [l(h_theta (x), y)]$
$D$ denotes the true distribution over samples. $D = {(x_i, y_i) tilde math.italic(D)}, i = 1,...,m$

The empirical risk is the average loss over a finite training set:
$hat(R)(h_theta, D) = 1/(|D|) sum_(i=1)^m l(h_theta (x_i), y_i)$
We ust testset to estimate the true risk. $hat(R)(h_theta, D_"test")$

- adversarial risk
The adversarial risk of a classifier is the expected worst-case loss under allowed perturbations (some region around the sample point):

$R_"adv"(h_theta) = E_(x,y) tilde D [max_(delta in Delta) l(h_theta (x+delta), y)]$

Here explicitly allow that the perturbation region Î”(x) can depend on the sample point itself; using the examples from the previous sections, this would be necessary in order to ensure that perturbations respected the *ultimate image bounds* (e.g., pixel values in [0, 1]) after perturbation.

The empirical adversarial risk is the average worst-case loss over a finite training set:

$hat(R)_"adv"(h_theta, D) = 1/(|D|) sum_(i=1)^m max_(delta in Delta) l(h_theta (x_i + delta), y_i)$

When we prefer to use the adversarial risk as our measure of performanceï¼š
1. Several classification tasks (especially those relating to computer security) such as spam classification, malware detection, network intrusion detection, etc, are genuinely adversarial, where attackers have an direct incentive to fool a classifier. 

2.  It is very difficult to actually draw samples i.i.d. from the true underlying distribution. Instead, any procedure we use to collect data is an empirical attempt at accessing the true underlying distribution, and may ignore certain dimensions, especially if these appear â€œobviousâ€ to humans. This is hopefully somewhat obvious even on the previous image classification example. 

=== Training adversarially robust classifiers

We can train adversarially robust classifiers by minimizing the empirical adversarial risk over a training set, which is a min-max optimization problem:

$min_(theta) hat(R)_"adv"(h_theta, D) = min_(theta) 1/(|D|) sum_(i=1)^m max_(delta in Delta) l(h_theta (x_i + delta), y_i)$

The inner maximization problem is generally hard to solve exactly, the gradient of the inner function involving the maximization term is simply given by the gradient of the function evaluated at this maximum. In other words, letting $Î´^*$ denote the optimum of the inner optimization problem.

$delta^* = "argmax"_(delta in Delta(x)) l(h_theta (x+ delta), y)$

the gradient we require is simply given by:

$nabla_(theta) max_(delta in Delta(x)) l(h_theta (x+ delta), y) = nabla_(theta) l(h_theta (x + delta^*), y)$

Iteratively compute adversarial examples, and then update the classifier based not upon the original data points

åœ¨å®žè·µä¸­å¸¸ç”¨ PGD æ¥è¿‘ä¼¼å†…å±‚æœ€å¤§åŒ–ï¼Œå› æ­¤ PGD adversarial training è¢«è®¤ä¸ºæ˜¯å½“å‰æœ€æœ‰æ•ˆä¸”æœ€ç¨³å®šçš„é˜²å¾¡æ–¹æ³•ã€‚

=== æœ€ç»ˆcomments

å¯¹æŠ—é²æ£’æ€§å…¶å®žå¯ä»¥ç»Ÿä¸€åœ°çœ‹ä½œæ˜¯ä¸€ä¸ªé²æ£’ä¼˜åŒ–é—®é¢˜ï¼Œå³ã€Œå†…å±‚æœ€å¤§åŒ–ã€ï¼ˆæ”»å‡»ï¼‰å’Œã€Œå¤–å±‚æœ€å°åŒ–ã€ï¼ˆé˜²å¾¡ï¼‰

æ‰€æœ‰å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨å°è¯•è§£å†³ å†…å±‚æœ€å¤§åŒ–ï¼ˆåœ¨å…è®¸æ‰°åŠ¨èŒƒå›´å†…å¯»æ‰¾æœ€åçš„è¾“å…¥æ‰°åŠ¨ï¼Œæœ€å¤§åŒ–æ¨¡åž‹æŸå¤±ï¼‰ã€‚

æ‰€æœ‰é˜²å¾¡æ–¹æ³•ï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯åœ¨å°è¯•è§£å†³ å¤–å±‚æœ€å°åŒ–ï¼ˆåœ¨å¯¹æŠ—æ‰°åŠ¨å­˜åœ¨çš„æƒ…å†µä¸‹è®­ç»ƒæˆ–æ”¹è¿›æ¨¡åž‹ï¼Œä½¿æŸå¤±æœ€å°ï¼‰ã€‚

è®¸å¤šç ”ç©¶æ²¡æœ‰ä»Žâ€œä¼˜åŒ–é—®é¢˜â€çš„è§’åº¦æ¥é˜è¿°è‡ªå·±çš„æ–¹æ³•ï¼Œè€Œæ˜¯å¼ºè°ƒâ€œç”¨äº†ä»€ä¹ˆæ‰‹æ®µâ€ã€‚

è¿™å¯¼è‡´å‡ºçŽ°äº†å¤§é‡åå­—ä¸åŒã€æ–¹æ³•çœ‹ä¼¼äº”èŠ±å…«é—¨çš„æ”»å‡»/é˜²å¾¡æ‰‹æ®µï¼Œä½†å®ƒä»¬å…¶å®žéƒ½åªæ˜¯å¯¹æ ¸å¿ƒä¼˜åŒ–é—®é¢˜çš„ç»†å¾®å˜ä½“ï¼š

- åœ¨æ‰°åŠ¨çš„çº¦æŸä¸Šä½¿ç”¨ä¸åŒçš„èŒƒæ•°

- ç”¨ä¸åŒçš„ä¼˜åŒ–ç®—æ³•æ¥è§£å†…å±‚æœ€å¤§åŒ–é—®é¢˜ã€‚

- ä½¿ç”¨ä¸€äº›çœ‹ä¼¼å¤æ‚ç”šè‡³â€œèŠ±å“¨â€çš„æŠ€å·§ï¼Œä½†æœªå¿…ä¸Žé²æ£’ä¼˜åŒ–æ¡†æž¶æœ‰æ˜Žç¡®å…³ç³»ã€‚

ï¼ˆZico å’Œ Aleksander çš„ä¸ªäººæ„è§ï¼‰

- è¿‡åº¦ä¾èµ–è¿™äº›â€œå¯å‘å¼æ–¹æ³•â€çš„åŽ†å²è¡¨çŽ°ä¸å¥½ï¼Œå¾ˆå¤šæ–¹æ³•çœ‹ä¼¼æ–°é¢–ï¼Œä½†æ•ˆæžœå’Œç†è®ºè”ç³»ä¸å¼ºï¼Œæœ€åŽå¾€å¾€æ²¡æœ‰æŒç»­å½±å“åŠ›ã€‚

- ä»–ä»¬çš„è§‚ç‚¹æ˜¯ï¼šçœŸæ­£é‡è¦çš„æ˜¯å›žåˆ°ä¼˜åŒ–é—®é¢˜çš„æœ¬è´¨ï¼Œè€Œä¸æ˜¯æ²‰è¿·äºŽå„ç§äº”èŠ±å…«é—¨çš„â€œæŠ€å·§åŒ–å‘½åâ€ã€‚

== Adversarial examples in Linear Models

ä¼˜åŒ–ï¼š

çº¿æ€§äºŒåˆ†ç±»æ˜¯å”¯ä¸€èƒ½â€œç²¾ç¡®è§£å‡ºå¯¹æŠ—é²æ£’è®­ç»ƒâ€çš„æƒ…å†µï¼šå†…å±‚æœ€å¤§åŒ–æœ‰è§£æžè§£ï¼Œå¤–å±‚å‡¸ä¼˜åŒ–å¯å…¨å±€è§£ã€‚


ç­‰ä»·ï¼š
ç­‰ä»·äºŽå¯¹æŠ—è®­ç»ƒç­‰ä»·äºŽåœ¨åŽŸå§‹æ•°æ®ä¸Šæ·»åŠ ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼š

ç»“æžœï¼š
æ™®é€šæ¨¡åž‹æžæ˜“è¢«å¯¹æŠ—æ ·æœ¬æ¬ºéª—ï¼ˆé«˜è„†å¼±æ€§ï¼‰ï¼›é²æ£’æ¨¡åž‹èƒ½æœ‰æ•ˆé™ä½Žæ”»å‡»æˆåŠŸçŽ‡ï¼Œä½† clean accuracy ä¼šä¸‹é™ã€‚

== Adversarial examples in Deep Learning
- é«˜ç»´æ€§å¸¦æ¥çš„è„†å¼±æ€§

  - åœ¨é«˜ç»´è¾“å…¥ç©ºé—´ä¸­ï¼Œå‡ ä¹Žä»»ä½•ç‚¹éƒ½å­˜åœ¨ä¸€ä¸ªæ–¹å‘èƒ½æ˜¾è‘—å¢žåŠ æŸå¤±ã€‚

  - è¿™æ„å‘³ç€å³ä½¿å¾ˆå°çš„è¾“å…¥æ‰°åŠ¨ï¼Œä¹Ÿä¼šå¯¼è‡´æŸå¤±å¤§å¹…ä¸Šå‡ï¼Œä»Žè€Œäº§ç”Ÿå¯¹æŠ—æ ·æœ¬ã€‚

  - æ¢å¥è¯è¯´ï¼šæ·±åº¦ç½‘ç»œçš„æŸå¤±é¢å¤©ç„¶å®¹æ˜“äº§ç”Ÿâ€œå°–é”æ–¹å‘â€ï¼Œæ‰€ä»¥ç‰¹åˆ«å®¹æ˜“è¢«å¯¹æŠ—æ”»å‡»ã€‚

- éžå‡¸æ€§å¸¦æ¥çš„å†…å±‚æœ€å¤§åŒ–å›°éš¾

    - ä¸Žçº¿æ€§åˆ†ç±»ä¸åŒï¼Œæ·±åº¦ç½‘ç»œè¾“å…¥ç©ºé—´çš„æŸå¤±å‡½æ•°é«˜åº¦éžå‡¸ã€‚

    - è¿™ä½¿å¾—å†…å±‚æœ€å¤§åŒ–é—®é¢˜ï¼ˆå¯»æ‰¾æœ€åæ‰°åŠ¨ï¼‰éš¾ä»¥ç²¾ç¡®æ±‚è§£ï¼Œä¹Ÿéš¾ä»¥ä¸Šç•Œã€‚

    - æ¢¯åº¦æ–¹å‘å¯èƒ½åªæ˜¯å±€éƒ¨æœ€ä¼˜ï¼Œåˆå§‹ç‚¹ä¸åŒä¼šå¯¼è‡´ä¸åŒç»“æžœã€‚

    - å¯¹äºŽæ”»å‡»æ¥è¯´é—®é¢˜ä¸å¤§ï¼šå› ä¸ºâ€œåˆ°å¤„éƒ½æœ‰å±é™©æ–¹å‘â€ï¼Œå³ä½¿ä¸æ˜¯æœ€ä¼˜æ‰°åŠ¨ä¹Ÿèƒ½æˆåŠŸã€‚

    - ä½†å¯¹è®­ç»ƒé²æ£’æ¨¡åž‹æ¥è¯´æ˜¯ä¸¥é‡é—®é¢˜ï¼š

    - Danskin å®šç†å¤±æ•ˆï¼ˆæ¢¯åº¦ä¸èƒ½ç®€å•åœ°ç­‰äºŽåœ¨æœ€ä¼˜æ‰°åŠ¨ç‚¹çš„æ¢¯åº¦ï¼‰ã€‚

    - æ— æ³•æŠŠ min-max é—®é¢˜åŒ–ç®€ä¸ºå¹²å‡€çš„å¤–å±‚æœ€å°åŒ–ã€‚


=== Solving the inner maximization
è¿‘ä¼¼æ±‚è§£å†…å±‚æœ€å¤§åŒ–ï¼ˆæ‰¾æœ€åæ‰°åŠ¨ï¼‰æœ‰ä¸‰æ¡ä¸»çº¿ï¼Œå„è‡ªå¯¹åº”â€œä¸‹ç•Œâ€”ç²¾ç¡®â€”ä¸Šç•Œâ€çš„æ€è·¯ä¸Žå–èˆã€‚

- Lower bounding ä¸‹ç•Œï¼ˆåŸºäºŽæ”»å‡»çš„ç»éªŒæ±‚è§£ï¼‰---- æœ€å¸¸è§

    - åšæ³•ï¼šç›´æŽ¥åœ¨çº¦æŸé›†å†…æ‰¾ä¸€ä¸ªå¯è¡Œæ‰°åŠ¨ Î´ ä½¿æŸå¤±å°½é‡å¤§ï¼ˆå¦‚æ¢¯åº¦æ³•/PGD/å¤šé‡é‡å¯/å¯å‘å¼æœç´¢ï¼‰ã€‚
    - å«ä¹‰ï¼šä»»ä½•æ‰¾åˆ°çš„å¯è¡Œå€¼éƒ½æ˜¯ç›®æ ‡çš„ä¸‹ç•Œï¼ˆâ‰¥0 çš„æœ€åå€¼çš„ä¸€éƒ¨åˆ†ï¼‰ã€‚
    - ä¼˜ç‚¹ï¼šæœ€å¸¸ç”¨ã€æ˜“æ‰©å±•åˆ°å¤§æ¨¡åž‹ï¼›èƒ½äº§å‡ºçœŸå®žå¯¹æŠ—æ ·æœ¬ï¼›ä¹Ÿå¯ç”¨äºŽå¯¹æŠ—è®­ç»ƒ

    - å±€é™ï¼šä¸ä¿è¯å…¨å±€æœ€ä¼˜ï¼›æ”»å‡»ä¸å¤Ÿå¼ºä¼šä½Žä¼°æœ€åæŸå¤± â†’ è®­ç»ƒä¸Žè¯„æµ‹å¯èƒ½â€œè™šé«˜â€ã€‚

- ç²¾ç¡®æ±‚è§£ï¼ˆç»„åˆä¼˜åŒ–/MIP/åˆ†æžå®šç•Œï¼‰

    - åšæ³•ï¼šæŠŠ ReLU ç­‰éžçº¿æ€§ç¼–ç æˆæ•´æ•°çº¦æŸï¼Œæž„é€ æˆæ··åˆæ•´æ•°è§„åˆ’ç­‰ç²¾ç¡®æ¨¡åž‹æ±‚è§£ã€‚

    - å«ä¹‰ï¼šèƒ½ç»™å‡ºçœŸÂ·æœ€ä¼˜å€¼ä¸Žå¯¹åº”æœ€ä¼˜æ‰°åŠ¨ã€‚

    - ä¼˜ç‚¹ï¼šæœ‰â€œé‡‘æ ‡å‡†â€ä½œç”¨ï¼Œå¯ç”¨äºŽå°ç½‘ç»œ/å°æ•°æ®ä¸¥æ ¼è¯„ä¼°æˆ–åšç ”ç©¶å¯¹ç…§ã€‚

    - å±€é™ï¼šä¸å¯æ‰©å±•åˆ°å¤§è§„æ¨¡çŽ°ä»£ç½‘ç»œï¼›è®¡ç®—ä»£ä»·æžé«˜ã€‚

- ä¸Šç•Œï¼ˆå‡¸æ¾å¼›/åŒºé—´ä¼ æ’­/å¯¹å¶è¯æ® â†’ è®¤è¯é²æ£’ï¼‰

    - åšæ³•ï¼šå¯¹ç½‘ç»œä½œå‡¸æ¾å¼›/çº¿æ€§ä¸Šã€ä¸‹ç•Œé€¼è¿‘ï¼Œåœ¨æ¾å¼›æ¨¡åž‹ä¸Šâ€œæœ€å¤§åŒ–æŸå¤±â€å¾—åˆ°å¯è®¡ç®—çš„ä¸Šç•Œï¼›æˆ–ç”¨å¯¹å¶å½¢å¼ç›´æŽ¥ç»™å‡ºä¸Šç•Œã€‚

    - å«ä¹‰ï¼šå¦‚æžœä¸Šç•Œä¹Ÿå¾ˆå°ï¼Œå°±èƒ½è¯æ˜Žåœ¨ç»™å®š Ïµ ä¸‹ä¸å­˜åœ¨æˆåŠŸæ”»å‡»ï¼ˆ=â€œè®¤è¯é²æ£’â€ï¼‰ã€‚

    - ä¼˜ç‚¹ï¼šç»™å‡ºå¯è¯æ˜Žä¿è¯ï¼›ä¸Žè®­ç»ƒç»“åˆï¼ˆè®¤è¯è®­ç»ƒ/æ¾å¼›å¯¹æŠ—è®­ç»ƒï¼‰å¯èŽ·å¾—å¯è¯æ˜Žé²æ£’çš„ SOTA æ–¹æ³•æ—ã€‚

    - å±€é™ï¼šä¸Šç•Œå¯èƒ½æ¾ï¼›æž„é€ çœŸå®žæ ·æœ¬å¹¶éžç›®æ ‡ï¼›å®žçŽ°å¤æ‚ï¼Œè§„æ¨¡åŒ–ä»æœ‰æˆæœ¬ã€‚


=== Lower bounding
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¿¡æ¯æ¥å¯»æ‰¾ä¸€ä¸ªå±€éƒ¨æœ€ä¼˜çš„æ‰°åŠ¨ $delta$ï¼Œä»Žè€Œå¾—åˆ°å†…å±‚æœ€å¤§åŒ–é—®é¢˜çš„ä¸€ä¸ªä¸‹ç•Œã€‚å½“ç„¶æˆ‘ä»¬éœ€è¦ä¿è¯ $delta$ åœ¨å…è®¸çš„æ‰°åŠ¨èŒƒå›´ $Delta$ å†…ã€‚
- The Fast Gradient Sign Method (FGSM)
æˆ‘ä»¬å¸Œæœ›è®©$delta$æœç€æ¢¯åº¦çš„æ–¹å‘è¡ŒåŠ¨ï¼Œé‚£ä¹ˆè¿™ä¸€æ­¥çš„å¤§å°åº”è¯¥æ˜¯å¤šå¤§å‘¢ï¼Ÿæˆ‘ä»¬å¸Œæœ›è¿™ä¸€æ­¥å°½å¯èƒ½å¤§ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è®©$delta$ç­‰äºŽåœ¨å…è®¸èŒƒå›´å†…çš„æœ€å¤§å€¼ï¼š

$delta = epsilon * "sign"(nabla_x l(h_theta (x), y))$


```

def fgsm(model, X, y, epsilon):
    """ Construct FGSM adversarial examples on the examples X"""
    delta = torch.zeros_like(X, requires_grad=True)
    loss = nn.CrossEntropyLoss()(model(X + delta), y)
    loss.backward()
    return epsilon * delta.grad.detach().sign()
    
    ```

FGSMæ˜¯ä¸€ä¸ªåœ¨$L_"inf"$ä¸‹çš„å•æ­¥æ”»å‡»æ–¹æ³•ï¼Œæ˜¯å¯¹æŠ—æ”»å‡»çš„â€œå…¥é—¨åŸºçº¿â€ã€‚ä¹Ÿå¯ä»¥æŠŠå…¶æ³›åŒ–ä¸ºå…¶ä»–normä¸‹çš„å•æ­¥æ”»å‡»ã€‚

FGSMå¯¹äºŽä¸€ä¸ªçº¿æ€§äºŒåˆ†ç±»å™¨æ¥è¯´å°±æ˜¯æœ€ä¼˜çš„æ”»å‡»æ–¹æ³•ã€‚ä»–é€šè¿‡æ¨¡åž‹çš„æ¢¯åº¦å‡è®¾äº†ä¸€ä¸ªæ¨¡åž‹çš„çº¿æ€§ä¼°è®¡ã€‚æˆ‘ä»¬ä¹ŸçŸ¥é“æ¨¡åž‹å¹¶éžçº¿æ€§çš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é€šè¿‡å¤šæ¬¡è¿­ä»£FGSMæ¥èŽ·å¾—æ›´å¼ºçš„æ”»å‡»æ–¹æ³•ï¼Œè¿™å°±æ˜¯PGDæ”»å‡»ã€‚

- Projected gradient descent (PGD) attack
é‡å¤$delta := P(delta + alpha nabla_(delta)l(h_theta (x+ delta), y))$. Pæ­¥éª¤æ˜¯ä¸€ä¸ªæŠ•å½±æ­¥éª¤ï¼Œä¿è¯$delta$åœ¨å…è®¸çš„æ‰°åŠ¨èŒƒå›´å†…ã€‚

```
def pgd(model, X, y, epsilon, alpha, num_iter):
    """ Construct FGSM adversarial examples on the examples X"""
    delta = torch.zeros_like(X, requires_grad=True)
    for t in range(num_iter):
        loss = nn.CrossEntropyLoss()(model(X + delta), y)
        loss.backward()
        delta.data = (delta + X.shape[0]*alpha*delta.grad.data).clamp(-epsilon,epsilon)
        delta.grad.zero_()
    return delta.detach()

```
åœ¨è¿™ä¸ªä¾‹å­é‡Œé¢ï¼Œ$alpha$è®¾ç½®å¾—å¾ˆå¤§ï¼Œæ˜¯1e4,å› ä¸ºgradç›¸å¯¹äºŽ$delta$æ¥è¯´æ˜¯å¾ˆå°çš„ã€‚

é™¤æ­¤ä¹‹å¤–ï¼ŒPSDçš„æ”»å‡»é€‰æ‹©æœ€é™¡å³­çš„æ¢¯åº¦çš„æ—¶å€™ï¼Œå¹¶ä¸æ˜¯ä¼ ç»Ÿæ„ä¹‰ä¸Šæœ€å¤§çš„æ¢¯åº¦ï¼Œè€Œæ˜¯ä¸€ä¸ªç»è¿‡å½’ä¸€åŒ–çš„æ¢¯åº¦ï¼Œä¸€ä¸ªnormalized steepest descentã€‚

è¿˜æœ‰ä¸€ä¸ªæ–¹æ³•æ˜¯å¤šæ¬¡éšæœºåˆå§‹åŒ–PGDæ”»å‡»ï¼Œæ¥èŽ·å¾—æ›´å¼ºçš„æ”»å‡»ã€‚è¿™ä¸ªæ–¹æ³•çŽ°å®žä¸­æ¯”è¾ƒæ˜‚è´µã€‚

- Targeted attack
ç¨å¾®æ›´å›°éš¾çš„æ˜¯æœ‰ç›®æ ‡çš„æ”»å‡»ï¼Œæˆ‘ä»¬å¸Œæœ›è®©æ¨¡åž‹æŠŠ$x+ delta$åˆ†ç±»åˆ°ä¸€ä¸ªç‰¹å®šçš„ç±»åˆ«$y_"target"$ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æœ€å¤§åŒ–$h_theta (x + delta)_(y_"target") - h_theta (x+delta)_y$æ¥å®žçŽ°è¿™ä¸ªç›®æ ‡ã€‚


- Non $L_"inf"$ attacks

å¯ä»¥ä»Ž l_inf èŒƒæ•°æ”»å‡»æŽ¨å¹¿åˆ°å…¶ä»–èŒƒæ•°æ”»å‡»ã€‚æ¯”å¦‚è½¬åˆ°l2èŒƒæ•°ï¼Œå…­
çƒäº‹$sqrt(n)$å¤§å°çš„l_infçš„çƒï¼Œå› æ­¤éœ€è¦ç¼‡å¨œåŠ ä¸Šä¸€ä¸ª$sqrt(2)/sqrt(pi e)$çš„scaling factorã€‚

å…¶ä»–çš„æ”»å‡»è¦ä¹ˆæ˜¯é’ˆå¯¹ä¸åŒçš„norm ball pertubation è¦ä¹ˆæ˜¯ä¸åŒçš„ä¼˜åŒ–norm ballçš„æ–¹æ³•ã€‚

=== Exactly solving the inner maximization (combinatorial optimization)

=== Upper bounding the inner maximization

== Adversarial training, solving the outer minimization
æˆ‘ä»¬å‡è®¾ï¼Œå¯¹äºŽmin-maxé—®é¢˜çš„å†…éƒ¨æ¥è¯´ï¼Œå¯¹æŠ—æ ·æœ¬æ˜¯æœ‰ç€è¿™ä¸ªæ¨¡åž‹çš„å…¨éƒ¨çŸ¥è¯†çš„ï¼Œä»–ä»¬å¯ä»¥åŽ»è¢«ç‰¹åŒ–è€Œæ”»å‡»æ¨¡åž‹ï¼Œæ— è®ºè¿™ä¸ªæ¨¡åž‹æ‹¥æœ‰ä»€ä¹ˆæ ·çš„å‚æ•°ã€‚ï¼ˆè¿™äº›æˆ‘ä»¬åœ¨å¤–éƒ¨minè®­ç»ƒå‡ºæ¥çš„å‚æ•°ï¼‰ã€‚
min-maxé—®é¢˜çš„ç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ªé²æ£’çš„ä¼˜åŒ–é—®é¢˜ã€‚

å½“ç„¶å®žé™…ä¸Šæ”»å‡»æ–¹å¹¶ä¸ä¸€å®šçŸ¥é“æ¨¡åž‹çš„å…¨éƒ¨ä¿¡æ¯ï¼Œç”šè‡³å¯èƒ½ä¸çŸ¥é“æ¨¡åž‹çš„æž¶æž„å’Œå‚æ•°ã€‚å¯¹äºŽæ”»å‡»æ–¹çš„â€œèƒ½åŠ›â€çš„å¤§å°å¹¶ä¸å¥½ç•Œå®šï¼Œä½†æ˜¯å¯¹äºŽèƒ½åŠ›çš„å‡è®¾å¾ˆé‡è¦ã€‚è¯„ä¼°æ¨¡åž‹æ—¶è¦è°¨æ…Žï¼šå¦‚æžœåªåœ¨å¼±æ”»å‡»ä¸‹è¯„ä¼°ï¼Œæ¨¡åž‹å¯èƒ½è¡¨é¢é²æ£’ä½†å®žé™…å®¹æ˜“è¢«æ›´å¼ºçš„æ”»å‡»ç ´åã€‚

Danskin è¦æ±‚â€œç²¾ç¡®æœ€å¤§åŒ–â€ï¼šå®šç†çš„æ¡ä»¶æ˜¯å†…å±‚çš„max èƒ½è¢«ç¡®åˆ‡æ±‚è§£ï¼ˆä¸”ä¸€äº›å¯å¾®æ€§/ç´§æ€§æ¡ä»¶æˆç«‹ï¼‰ï¼Œè¿™æ—¶å¤–å±‚å…³äºŽ ðœƒçš„æ¢¯åº¦ç­‰äºŽåœ¨$Î´^*$æœ€ä¼˜å¤„å¯¹ ð‘“ çš„æ¢¯åº¦ã€‚

æ·±ç½‘é‡Œé€šå¸¸ä¸èƒ½ç²¾ç¡®æ±‚è§£å†…å±‚ï¼šå†…å±‚æ˜¯éžå‡¸ã€å¯èƒ½æœ‰å¤šæžå€¼ã€ä¸”æœ€ä¼˜è§£å¯èƒ½ä¸æ˜¯å”¯ä¸€ã€‚å› è€Œä¸¥æ ¼çš„ Danskin æ¡ä»¶é€šå¸¸ä¸æˆç«‹â€”â€”ç†è®ºä¸Šä¸èƒ½æŠŠå¤–å±‚æ¢¯åº¦ç­‰åŒä¸ºåœ¨æŸä¸ªâ€œå…¨å±€æœ€ä¼˜æ‰°åŠ¨â€å¤„çš„æ¢¯åº¦ã€‚ä½†ç»éªŒä¸Šï¼Œâ€œè¿‘ä¼¼æœ€å¤§åŒ–åšå¾—è¶Šå¥½ï¼ŒDanskin çš„ç»“è®ºè¶Šè¿‘ä¼¼æˆç«‹â€ã€‚
å› æ­¤åœ¨å¯¹æŠ—è®­ç»ƒé‡Œçš„å®žåŠ¡å«ä¹‰ï¼š

- è‹¥ä½ ç”¨å¼±çš„æ”»å‡»ï¼ˆä¾‹å¦‚å•æ­¥ FGSM æˆ–æ­¥æ•°ä¸è¶³çš„ PGDï¼‰ä½œä¸ºå†…å±‚ï¼Œå¾—åˆ°çš„â€œé²æ£’è®­ç»ƒâ€ä¼šä½Žä¼°çœŸå®žæœ€åæƒ…å½¢â€”â€”è®­ç»ƒå‡ºçš„æ¨¡åž‹å®¹æ˜“è¢«æ›´å¼ºæ”»å‡»æ‰“ç©¿ã€‚

- æ‰€ä»¥è¦æƒ³å¾—åˆ°â€œæ›´çœŸçš„â€é²æ£’æ€§ï¼ˆå³è®© Danskin è¿‘ä¼¼æ›´æˆç«‹/è®©å¤–å±‚æ¢¯åº¦æ›´å¯ä¿¡ï¼‰ï¼Œéœ€è¦æŠŠå°½å¯èƒ½å¼ºçš„æ”»å‡»åµŒå…¥å†…å±‚ï¼ˆå¤šæ­¥ PGDã€é‡å¯ã€è¾ƒå°æ­¥é•¿ç­‰ï¼‰ã€‚ç¤¾åŒºå®žè·µä¹Ÿè¡¨æ˜Žï¼šå¤šæ­¥ PGDï¼ˆå¸¦é‡å¯ï¼‰æ˜¯ç›®å‰æœ€å¯é çš„ç»éªŒå†…å±‚æ±‚è§£å™¨ä¹‹ä¸€ã€‚

ä¸ä¸¥æ ¼æ‹¥æœ‰æ•°å­¦ä¿è¯ã€‚

æ˜¾ç¤ºå®žçŽ°:
```
def pgd_linf(model, X, y, epsilon=0.1, alpha=0.01, num_iter=20, randomize=False):
    """ Construct FGSM adversarial examples on the examples X"""
    if randomize:
        delta = torch.rand_like(X, requires_grad=True)
        delta.data = delta.data * 2 * epsilon - epsilon
    else:
        delta = torch.zeros_like(X, requires_grad=True)
        
    for t in range(num_iter):
        loss = nn.CrossEntropyLoss()(model(X + delta), y)
        loss.backward()
        delta.data = (delta + alpha*delta.grad.detach().sign()).clamp(-epsilon,epsilon)
        delta.grad.zero_()
    return delta.detach()
```

è€Œå¯¹äºŽä¸€ä¸ªepochçš„è®­ç»ƒæ¥è¯´ï¼Œ
```
    delta = attack(model, X, y, **kwargs)
    yp = model(X+delta)
```
æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªattackæ›¿æ¢æŽ‰äº†åŽŸæœ¬çš„è®­ç»ƒã€‚
```
    yp = model(X)
```

=== Evaluating robust Models
è¿™é‡Œéœ€è¦éžå¸¸å°å¿ƒï¼šæˆ‘ä»¬å¯ä»¥éžå¸¸ç®€ç­”åœ°è®©æ¨¡åž‹ä¿®æ”¹æ¥å¯¹æŠ—ä¸€ä¸ªç‰¹å®šçš„æ”»å‡»æ–¹æ³•ï¼Œä½†æˆ‘ä»¬å¯ä»¥è½»æ˜“åœ°è¢«å¦ä¸€ä¸ªä¸åŒçš„æ”»å‡»æ–¹å¼æ‰€æ„šå¼„ã€‚

å› æ­¤

1. åˆ«ç”¨â€œé”™å¨èƒæ¨¡åž‹â€æ¥è¯„ä¼°
ç”¨ â„“âˆž å¨èƒæ¨¡åž‹è®­ç»ƒå‡ºæ¥çš„é²æ£’æ¨¡åž‹ï¼Œå¦‚æžœæ‹¿åŽ»ç”¨ â„“2 æ”»å‡»è¯„ä¼°ï¼Œç»“è®ºåŸºæœ¬æ²¡æ„ä¹‰ï¼ˆæœ€å¤šæ»¡è¶³å¥½å¥‡å¿ƒï¼‰ã€‚å› ä¸ºæ¨¡åž‹åªé’ˆå¯¹è®­ç»ƒæ—¶çš„æ‰°åŠ¨é›†å­¦ä¼šäº†é˜²å¾¡ï¼Œæ¢äº†å¨èƒæ¨¡åž‹è‡ªç„¶ä¸é²æ£’ã€‚

2. æƒ³è¦â€œè·¨æ”»å‡»æ¨¡åž‹æ³›åŒ–â€ï¼Œå°±è¦åœ¨è®­ç»ƒæ—¶æ˜Žç¡®å¹¶è¦†ç›–è¿™äº›æ¨¡åž‹

3. çœŸæ­£æƒ³è¦çš„æ˜¯â€œäººç±»æ„ŸçŸ¥ä¸å˜â€çš„æ”»å‡»é›†ï¼Œä½†éš¾ä»¥åˆ»ç”»
ç†æƒ³çš„æ‰°åŠ¨é›†åº”æ˜¯â€œäººçœ‹èµ·æ¥è¿˜ä¸€æ ·â€çš„æ‰€æœ‰å›¾åƒï¼Œè¿™ä¸ªé›†åˆæžéš¾ç²¾ç¡®å®šä¹‰ï¼Œå› æ­¤æ˜¯å¾ˆå¥½çš„ç ”ç©¶æ–¹å‘ã€‚

=== å¯è§†åŒ–é²æ£’lossçš„è¡¨é¢

æ™®é€šå›¾çš„loss surfaceéžå¸¸ä¸å¹³æ»‘ï¼Œåœ¨æ¢¯åº¦æ–¹å‘ä¸Šå˜åŒ–å‰§çƒˆï¼Œä¸”åœ¨éšæœºæ–¹å‘ä¸Šä¹Ÿæœ‰è¾ƒå¤§å˜åŒ–ã€‚â€”â€”ï¼ˆå‚æ•°ç©ºé—´ä¸ä¸€å®šæ›´å¹³æ»‘ï¼šæœ‰ç ”ç©¶åšäº† Hessian åˆ†æžï¼Œå‘çŽ°å½“å¯¹æŠ—åŠå¾„ï¼ˆé¢„ç®—ï¼‰è¾ƒå¤§æ—¶ï¼Œå‚æ•°ç©ºé—´é‡Œçš„æžå°å€¼åè€Œå¯èƒ½æ›´å°–ï¼ˆsharperï¼‰ï¼Œå¹¶éžå¤„å¤„â€œæ›´å¹³â€ï¼Œ2020ï¼‰

è¿™é‡Œéœ€è¦æ¯”è¾ƒçš„é‡è¦ä¸€ç‚¹æ˜¯ z è½´çš„ç›¸å¯¹å˜åŒ–ï¼ˆé²æ£’å›¾çš„â€œèµ·ä¼â€åªæ˜¯å› ä¸ºä½¿ç”¨äº†æ›´å°çš„åˆ»åº¦ï¼›å¦‚æžœæ”¾åœ¨ç›¸åŒåˆ»åº¦ä¸‹ï¼Œç¬¬äºŒå¹…å›¾å‡ ä¹Žæ˜¯å®Œå…¨å¹³å¦çš„ï¼‰ã€‚
é²æ£’æ¨¡åž‹åœ¨æ¢¯åº¦æ–¹å‘ï¼ˆå³æœ€é™¡çš„æ–¹å‘ï¼‰å’Œéšæœºæ–¹å‘ä¸Šçš„æŸå¤±æ›²é¢éƒ½ç›¸å½“å¹³å¦ï¼›è€Œä¼ ç»Ÿè®­ç»ƒçš„æ¨¡åž‹åœ¨æ¢¯åº¦æ–¹å‘ä¸ŠæŸå¤±å˜åŒ–éžå¸¸å‰§çƒˆï¼Œå¹¶ä¸”åœ¨æ²¿æ¢¯åº¦æ–¹å‘ç§»åŠ¨ä¸€æ®µåŽï¼Œéšæœºæ–¹å‘ä¸Šä¹Ÿä¼šè¿…é€Ÿäº§ç”Ÿè¾ƒå¤§çš„å˜åŒ–ã€‚
å½“ç„¶ï¼Œè¿™å¹¶ä¸èƒ½ä¿è¯ä¸å­˜åœ¨æŸä¸ªæ–¹å‘ä¼šå¸¦æ¥æ€¥å‰§çš„æŸå¤±å¢žåŠ ï¼Œä½†è‡³å°‘æä¾›äº†ä¸€ç§çº¿ç´¢ï¼Œè¯´æ˜Žå¯èƒ½å‘ç”Ÿäº†ä»€ä¹ˆã€‚

æ€»ä¹‹ï¼Œé€šè¿‡åŸºäºŽ PGD çš„å¯¹æŠ—è®­ç»ƒå¾—åˆ°çš„æ¨¡åž‹ç¡®å®žè¡¨çŽ°å‡ºçœŸæ­£çš„é²æ£’æ€§ï¼šå®ƒä»¬çš„æŸå¤±æ›²é¢æœ¬èº«æ›´åŠ å…‰æ»‘ï¼Œè€Œä¸ä»…ä»…æ˜¯é€šè¿‡æŸç§â€œæŠ€å·§â€æ¥æŽ©ç›–çœŸæ­£çš„æŸå¤±ä¸Šå‡æ–¹å‘ã€‚
è‡³äºŽèƒ½å¦åœ¨å½¢å¼ä¸Šå¯¹è¿™ç§é²æ£’æ€§è¯´å¾—æ›´æ˜Žç¡®ï¼Œè¿˜æœ‰å¾…è¿›ä¸€æ­¥ç ”ç©¶ï¼Œè¿™æ˜¯å½“å‰æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶ä¸»é¢˜ã€‚


=== åŒºé—´ç•Œçš„è€ƒé‡
åŒºé—´ç•Œçš„è€ƒé‡ä½œä¸ºevaluationæ˜¯æ²¡ä»€ä¹ˆæ„ä¹‰çš„ï¼Œå› ä¸ºåŒºé—´ç•Œçš„è€ƒé‡æ˜¯ä¸€ä¸ªéžå¸¸æ¾çš„ä¸Šç•Œã€‚

è€Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å¼è€ƒè™‘è¿™äº›ä¸Šç•Œï¼Œç•Œå°±èƒ½çœŸæ­£å‘æŒ¥ä½œç”¨ã€‚

=== å¯¹äºŽ2018å¹´çš„æ€»ç»“
è¿™é‡Œåšçš„æµ‹è¯•éƒ½æ˜¯åœ¨minstä¸Šé¢çš„ï¼Œçœ‹èµ·æ¥æ¯”è¾ƒå®¹æ˜“ï¼Œä½†æ˜¯å³ä½¿åœ¨cifar10ä¸Šé¢ï¼Œé²æ£’é”™è¯¯çŽ‡å°±è¾¾åˆ°äº†55%ï¼Œè€Œæœ€å¥½çš„å¯è¯æ˜Žé²æ£’æ¨¡åž‹é”™è¯¯çŽ‡å‡èŒè¶…è¿‡äº†70%ã€‚å‡ ä¹Žè¿˜æ²¡æœ‰æ·±å…¥æŽ¢ç´¢è¿‡è®­ç»ƒæµç¨‹ã€ç½‘ç»œæž¶æž„ã€æ­£åˆ™åŒ–ç­‰æ–¹é¢çš„é€‰æ‹©ã€‚
